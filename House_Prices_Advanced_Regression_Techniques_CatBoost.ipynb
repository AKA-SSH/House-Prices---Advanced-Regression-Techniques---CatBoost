{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "wDWavn7EALP0",
        "68K25QnFApn3",
        "521FfnSGBs6I"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prerequisites"
      ],
      "metadata": {
        "id": "Fyiej3-X1Ln0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owIket-l0vTK"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets pandas-profiling optuna catboost --quiet --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import optuna\n",
        "import logging\n",
        "import catboost\n",
        "import pandas as pd\n",
        "import opendatasets as od\n",
        "\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from ydata_profiling import ProfileReport\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)"
      ],
      "metadata": {
        "id": "4fP4PahX2k_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_url= 'https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data'\n",
        "od.download(data_url)\n",
        "os.chdir('house-prices-advanced-regression-techniques')\n",
        "\n",
        "# forming datasets\n",
        "raw_train_dataset = pd.read_csv('train.csv')\n",
        "raw_test_dataset  = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMxVy-DE2-o_",
        "outputId": "8ce52656-d14b-48f4-9355-2912fd704ac8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading house-prices-advanced-regression-techniques.zip to ./house-prices-advanced-regression-techniques\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 199k/199k [00:00<00:00, 42.7MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extracting archive ./house-prices-advanced-regression-techniques/house-prices-advanced-regression-techniques.zip to ./house-prices-advanced-regression-techniques\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "0SiDQfUx-v3B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Visualization"
      ],
      "metadata": {
        "id": "9iLojuHOVC5M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selecting only those columns which have atleast 50% non-null values."
      ],
      "metadata": {
        "id": "heQ3nKpT_Ado"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "usable_columns= raw_train_dataset.columns[[x<=50 for x in (raw_train_dataset.isna().sum()*100/len(raw_train_dataset)).round(2)]]"
      ],
      "metadata": {
        "id": "-gBU044q-ocT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using `usable_columns` list for creating the new dataset."
      ],
      "metadata": {
        "id": "aTQZgNii_acX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset= raw_train_dataset[usable_columns]\n",
        "test_dataset=  raw_test_dataset[usable_columns[:-1]] #discounting SalePrice column from usable_columns"
      ],
      "metadata": {
        "id": "zNC7d1XN_XIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating profile report to understand the data for exercising the best imputation technique."
      ],
      "metadata": {
        "id": "XI2uVsNp_uL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data_profile_report= ProfileReport(train_dataset)\n",
        "#data_profile_report.to_file('data_profile_report.html')"
      ],
      "metadata": {
        "id": "WZdt3E0G_r5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "conclusion:\n",
        "- best numeric imputation technique: median\n",
        "- best categoric imputation technique: most_frequent"
      ],
      "metadata": {
        "id": "Rz87JapFAHUF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Column Segregation"
      ],
      "metadata": {
        "id": "wDWavn7EALP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_numerical_columns=  train_dataset.select_dtypes(exclude= ['object']).columns\n",
        "test_numerical_columns=   test_dataset.select_dtypes(exclude= ['object']).columns\n",
        "\n",
        "categorical_columns= train_categorical_columns= test_categorical_columns= train_dataset.select_dtypes(include= ['object']).columns"
      ],
      "metadata": {
        "id": "-YdFkY6ZAGwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** `BsmtQual`, `BsmtCond`, `BsmtExposure`, `BsmtFinType1`, `BsmtFinType2`, `GarageFinish`, `GarageQual`, `GarageCond` have NA value which means that feature is `absent` in the house. Hence, filling the NA values with `absent` label."
      ],
      "metadata": {
        "id": "aFsIVNnZAVZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[train_categorical_columns]= train_dataset[train_categorical_columns].fillna('absent')\n",
        "test_dataset[test_categorical_columns]=   test_dataset[test_categorical_columns].fillna('absent')"
      ],
      "metadata": {
        "id": "h91OfMXFARfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Numerical and Categorical Imputation"
      ],
      "metadata": {
        "id": "68K25QnFApn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this function identifies the column with missing values and impute them using the provided imputation technique\n",
        "def impute_columns(dataset, columns, imputation_technique):\n",
        "  columns_with_missing_data= [column for column in columns if dataset[column].isna().sum() != 0]\n",
        "  imputer= SimpleImputer(strategy= imputation_technique)\n",
        "\n",
        "  for column in columns_with_missing_data:\n",
        "    missing_rows= dataset[column].isna()\n",
        "    imputed_values= imputer.fit_transform(dataset[[column]])\n",
        "    dataset[column] = imputed_values"
      ],
      "metadata": {
        "id": "QK9W3_HrAxne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imputation of train_dataset\n",
        "impute_columns(train_dataset, train_numerical_columns, 'median')\n",
        "impute_columns(train_dataset, train_categorical_columns, 'most_frequent')\n",
        "\n",
        "# imputation of test_dataset\n",
        "impute_columns(test_dataset, test_numerical_columns, 'median')\n",
        "impute_columns(test_dataset, test_categorical_columns, 'most_frequent')"
      ],
      "metadata": {
        "id": "Zyaicp4lA0AN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Verifying Imputation"
      ],
      "metadata": {
        "id": "pm7w4E25Bc2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_null(dataset):\n",
        "  return dataset.isna().sum()[dataset.isna().sum() != 0]"
      ],
      "metadata": {
        "id": "nN8xLLmwBSDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_null(train_dataset), check_null(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJat00ilBhpC",
        "outputId": "fd38cde3-0288-49d1-d01d-5392d0afd833"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Series([], dtype: int64), Series([], dtype: int64))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Label Encoding"
      ],
      "metadata": {
        "id": "521FfnSGBs6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this function helps in label encoding the unique values of the concerned column after setting it in ascending order on the basis of mean SalePrice\n",
        "def label_encode(column, display= False):\n",
        "  encoding_order= train_dataset.groupby(column)['SalePrice'].mean().round(2).sort_values().index.to_list()\n",
        "\n",
        "  def categorize_column(dataset, column, encoding_order, display):\n",
        "    label_dictionary= {label: index for index, label in enumerate(encoding_order)}\n",
        "    if display == True:\n",
        "      print(label_dictionary)\n",
        "\n",
        "    dataset[column]= dataset[column].map(label_dictionary)\n",
        "\n",
        "  categorize_column(train_dataset, column, encoding_order, display)\n",
        "  categorize_column(test_dataset, column, encoding_order, display)"
      ],
      "metadata": {
        "id": "nlM77RReBkQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding all the categorical columns\n",
        "for column in categorical_columns:\n",
        "  label_encode(column)"
      ],
      "metadata": {
        "id": "lggIzJDsCamk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding two numerical columns\n",
        "label_encode('OverallQual', True)\n",
        "print()\n",
        "label_encode('OverallCond', True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_b9j4rNCoiU",
        "outputId": "aff56430-78c4-42e7-c64b-27188a1bc783"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9}\n",
            "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "e2E77jMfDPLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dividing the train_dataset into features and target\n",
        "features, target = train_dataset.iloc[:, :-1].copy(), train_dataset.iloc[:, -1].copy()"
      ],
      "metadata": {
        "id": "WFom7af5EKz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating objective function for optuna hypertuning\n",
        "def objective(trial):\n",
        "    parameter= {'iterations': trial.suggest_int('iterations', 10, 1000),\n",
        "                'learning_rate': trial.suggest_float('learning_rate', 0.001, 1.0),\n",
        "                'depth': trial.suggest_int('depth', 1, 16),\n",
        "                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 0.0, 10.0),\n",
        "                'border_count': trial.suggest_int('border_count', 1, 255),\n",
        "                'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 20),\n",
        "                'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
        "                'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.1, 1.0),\n",
        "                'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations', 1, 10)}\n",
        "\n",
        "    catboost_model = CatBoostRegressor(**parameter, random_seed=42)#, verbose=0)\n",
        "\n",
        "    score = cross_val_score(catboost_model, features, target, cv=5, scoring='neg_mean_squared_error')\n",
        "    return -score.mean()\n",
        "\n",
        "# create an optuna study and optimize the hyperparameters\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "best_parameters= study.best_params\n",
        "catboost_model = CatBoostRegressor(**best_parameters)"
      ],
      "metadata": {
        "id": "5RnXrMNXEQdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "catboost_model.fit(features, target)\n",
        "\n",
        "y_test_pred= catboost_model.predict(test_dataset)"
      ],
      "metadata": {
        "id": "0s_wC5N2GDdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission= pd.read_csv('sample_submission.csv')"
      ],
      "metadata": {
        "id": "rub2eDORO89e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission.SalePrice= y_test_pred\n",
        "submission.set_index('Id', inplace= True)"
      ],
      "metadata": {
        "id": "GWGYZZ42PQ4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv('First-Submission.csv')"
      ],
      "metadata": {
        "id": "iC_7lDI2PTsr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}